{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb72256",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda-11.6/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 116\n",
      "CUDA SETUP: Loading binary /data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda116_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: /data/installation/anaconda3/envs/lora did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# model_path = \"/data/jzheng36/model/instruct_gpt4chan_3epoch\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# ).to(device)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\u001b[39;00m\n\u001b[1;32m     33\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m LlamaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[0;32m---> 34\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mpipeline(\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     38\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m    \n\u001b[1;32m     43\u001b[0m )\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/transformers/modeling_utils.py:3236\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3233\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_enable_flash_attn_2(config, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map)\n\u001b[1;32m   3235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[0;32m-> 3236\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3238\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[1;32m   3239\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:961\u001b[0m, in \u001b[0;36mLlamaForCausalLM.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m--> 961\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mhidden_size, config\u001b[38;5;241m.\u001b[39mvocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:823\u001b[0m, in \u001b[0;36mLlamaModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mvocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx)\n\u001b[0;32m--> 823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([LlamaDecoderLayer(config) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:823\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mvocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx)\n\u001b[0;32m--> 823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\u001b[43mLlamaDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:630\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 630\u001b[0m     \u001b[43mLlamaAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_flash_attn_2_enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m LlamaFlashAttention2(config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m    633\u001b[0m )\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m LlamaMLP(config)\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:297\u001b[0m, in \u001b[0;36mLlamaAttention.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim, bias\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mattention_bias)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim, bias\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mattention_bias)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_key_value_heads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, bias\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mattention_bias)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_rope()\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/torch/nn/modules/linear.py:101\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/torch/nn/modules/linear.py:107\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/lora/lib/python3.9/site-packages/torch/nn/init.py:419\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    417\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(1)\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    GPTJForCausalLM,\n",
    "    GPT2Tokenizer,\n",
    "    LlamaForCausalLM, \n",
    "    LlamaTokenizer,\n",
    ")\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "import transformers\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# model_path = \"/data/jzheng36/Fine-Tune-Llama2-/llama2_ft_7B-lr=2e-4\"\n",
    "# model_path = \"/data/shared/llama2/llama/7B-Chat/\"\n",
    "model_path = \"philschmid/llama-2-7b-instruction-generator\"\n",
    "\n",
    "# model_path = \"/data/jzheng36/model/instruct_gpt4chan_3epoch\"\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# # GPT-4chan\n",
    "# model = GPTJForCausalLM.from_pretrained(\n",
    "#     get_last_checkpoint(model_path) # 3, 10\n",
    "# ).to(device)\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
    "model = LlamaForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=200,\n",
    "    device=0,\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = \"\"\"\n",
    "        Asian people are just one of the many kinds of cancer in the world.\n",
    "        Which words in this sentence are about\n",
    "        1. dehumanization of disease\n",
    "        2. protected groups\n",
    "        no explanation, just tell me which words\n",
    "    \"\"\"\n",
    "    \n",
    "response = pipeline(text_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e7e238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T03:29:15.066827335Z",
     "start_time": "2023-11-02T03:29:15.057264276Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pathlib\n",
    "\n",
    "from termcolor import (\n",
    "    cprint,\n",
    "    colored\n",
    ")\n",
    "\n",
    "def extract_category(text):\n",
    "    patterns = [\n",
    "        r'Category: \\[(.*?)\\]',\n",
    "        r\"\\\\n \\\\n Category:(.*?) \\\\n \\\\n\",\n",
    "        r\"\\n \\n Category:(.*?) \\n\",\n",
    "        r'\\n Category:(.*?)\\\"',\n",
    "        r'\\n Category:(.*?)$'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def classify_by_twitter(sentence):\n",
    "    contents = [\n",
    "        'Hateful references: references forms of violence or violent events where a protected category was the primary target or victims, where the intent is to harass. This includes, but is not limited to media or text that refers to or depicts:genocides, (e.g., the Holocaust); lynchings.',\n",
    "        'Inciting fear: inciting fear or spreading fearful stereotypes about a protected category, including asserting that members of a protected category are more likely to take part in dangerous or illegal activities, e.g., “all [religious group] are terrorists.”',\n",
    "        'Inciting harass: inciting others to harass members of a protected category on or off platform, e.g., “I’m sick of these [religious group] thinking they are better than us, if any of you see someone wearing a [religious symbol of the religious group], grab it off them and post pics!“',\n",
    "        'Inciting discriminate: inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category, e.g., “If you go to a [religious group] store, you are supporting those [slur], let’s stop giving our money to these [religious slur].” This may not include content intended as political in nature, such as political commentary or content relating to boycotts or protests.',\n",
    "        'Inciting violence: content intended to incite violence against a protected category',\n",
    "        'Severe slurs and tropes: severe, repetitive usage of slurs, or racist/sexist tropes where the context is to harass or intimidate others',\n",
    "        'Moderate intimidate: moderate, isolated usage where the context is to harass or intimidate others',\n",
    "        'Dehumanization: dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.',\n",
    "        'Other: None of above.',\n",
    "    ]\n",
    "\n",
    "    # prefix = \"Classify the sentence into one of 9 categories below and response by format Category: [categories name]\\n\"\n",
    "    # prefix = \"Classify the following sentence into categories below \\\\n \\\\n Sentence:[\"+sentence + \"] \\n Here are categories:\\n\"\n",
    "    \n",
    "    prefix = \"Classify the following sentence into categories below\\n\\nSentence:[\"+sentence + \"]\\nHere are categories:\\n\"\n",
    "    content = \"\\n\\n\".join([\"- {}\".format(x) for x in random.sample(contents, k=len(contents))])\n",
    "\n",
    "    # prompt_template = \"{prefix}\\n{content}\\n\\nsentence: [{sentence}]\"\n",
    "    # prompt = prompt_template.format(prefix=prefix, content=content, sentence=sentence)\n",
    "    #prompt = prefix + content+ \" \\n \\n Hateful Sentence:[\"+sentence + \"]\"\n",
    "    prompt = prefix + content\n",
    "    \n",
    "    # res = pipeline(prefix + content+ \" \\\\n \\\\n Sentence:[\"+sentence + \"]\")\n",
    "    response = pipeline(prompt)\n",
    "    continuation = response[0]['generated_text'].replace(prompt, \"\")\n",
    "    \n",
    "    print(colored(prompt, \"red\") + colored(continuation, \"green\"))\n",
    "    \n",
    "    return continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "408e380b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentence into one of the categories. Here are the examples:\n",
      "- text: All Muslims are terrorists.\n",
      "- label: Inciting fear\n",
      "\n",
      "- text: The nigger should be burned alive in the town square and all of her kind should be exterminated. The kikes should be put in camps and gassed, and the chinks should be sent back to their own country. Lynching should be made legal again, and justice should be served without mercy.\n",
      "- label: Hateful references\n",
      "\n",
      "- text: If you go to a 99 ranch, you are supporting those chinks, let’s stop giving our money to these chinks.\n",
      "- label: Inciting discrimination\n",
      "\n",
      "- text: I’m sick of these Mulisms thinking they are better than us, if any of you see someone wearing a hijab, grab it off them and post pics!\n",
      "- label: Inciting harassment\n",
      "\n",
      "- text: It is time to put our hatred and frustrations into action. It is time to take action against those who we feel are oppressing us. We must fight back, and we must fight now!\n",
      "- label: Inciting violence\n",
      "\n",
      "- text: You're a worthless piece of shit, you stupid nigger. Go eat a bucket of fried chicken, you dumb monkey.\n",
      "- label: Slurs and trope\n",
      "\n",
      "- text: peta campaigns against keeping wild animals in zoos are right, let's switch them for some  nigger apes! they are fucking abhorrent\n",
      "- label: Dehumanization\n",
      "\n",
      "- text: Donald Trump is smelly pig.\n",
      "- label:\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"label\": \"Hateful references\",\n",
    "        \"index\": 1,\n",
    "        \"text\": \"The nigger should be burned alive in the town square and all of her kind should be exterminated. The kikes should be put in camps and gassed, and the chinks should be sent back to their own country. Lynching should be made legal again, and justice should be served without mercy.\",\n",
    "        \"description\": \"references forms of violence or violent events where a protected category was the primary target or victims, where the intent is to harass. This includes, but is not limited to media or text that refers to or depicts:genocides, (e.g., the Holocaust); lynchings.\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Inciting fear\",\n",
    "        \"index\": 2,\n",
    "        \"text\": \"All Muslims are terrorists.\",\n",
    "        \"description\": \"inciting others to harass members of a protected category on or off platform\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Inciting harassment\",\n",
    "        \"index\": 3,\n",
    "        \"text\": \"I’m sick of these Mulisms thinking they are better than us, if any of you see someone wearing a hijab, grab it off them and post pics!\",\n",
    "        \"description\": \"inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Inciting discrimination\",\n",
    "        \"index\": 4,\n",
    "        \"text\": \"If you go to a 99 ranch, you are supporting those chinks, let’s stop giving our money to these chinks.\",\n",
    "        \"description\": \"inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Inciting violence\",\n",
    "        \"index\": 5,\n",
    "        \"text\": \"It is time to put our hatred and frustrations into action. It is time to take action against those who we feel are oppressing us. We must fight back, and we must fight now!\",\n",
    "        \"description\": \"content intended to incite violence against a protected category\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Slurs and trope\",\n",
    "        \"index\": 6,\n",
    "        \"text\":  \"You're a worthless piece of shit, you stupid nigger. Go eat a bucket of fried chicken, you dumb monkey.\",\n",
    "        \"description\": \"slurs, tropes or other content that intends to degrade or reinforce negative or harmful stereotypes about a protected category\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Dehumanization\",\n",
    "        \"index\": 7,\n",
    "        \"text\": \"peta campaigns against keeping wild animals in zoos are right, let's switch them for some  nigger apes! they are fucking abhorrent\",\n",
    "        \"description\": \"dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.\"\n",
    "    },\n",
    "#     {\n",
    "#         \"label\": \"Other\",\n",
    "#         \"text\": \n",
    "#     },\n",
    "]\n",
    "\n",
    "text = \"Donald Trump is smelly pig.\"\n",
    "\n",
    "prefix = \"Classify the sentence into one of the categories. Here are the examples:\\n\"\n",
    "# prompt_template = \"\\n\\n\".join(\"- text: {}\\n- label: {}\\n- description: {}\".format(example[\"text\"], example[\"label\"], example[\"label\"]) \n",
    "#                               for example in random.sample(examples, k=len(examples)))\n",
    "prompt_template = \"\\n\\n\".join(\"- text: {}\\n- label: {}\".format(example[\"text\"], example[\"label\"]) \n",
    "                              for example in random.sample(examples, k=len(examples)))\n",
    "suffix = \"\\n\\n- text: {}\\n- label:\".format(text)\n",
    "\n",
    "\n",
    "text_input = prefix + prompt_template + suffix\n",
    "print(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36cd29f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mClassify the sentence into one of the categories. Here are the examples:\n",
      "- text: All Muslims are terrorists.\n",
      "- label: Inciting fear\n",
      "\n",
      "- text: The nigger should be burned alive in the town square and all of her kind should be exterminated. The kikes should be put in camps and gassed, and the chinks should be sent back to their own country. Lynching should be made legal again, and justice should be served without mercy.\n",
      "- label: Hateful references\n",
      "\n",
      "- text: If you go to a 99 ranch, you are supporting those chinks, let’s stop giving our money to these chinks.\n",
      "- label: Inciting discrimination\n",
      "\n",
      "- text: I’m sick of these Mulisms thinking they are better than us, if any of you see someone wearing a hijab, grab it off them and post pics!\n",
      "- label: Inciting harassment\n",
      "\n",
      "- text: It is time to put our hatred and frustrations into action. It is time to take action against those who we feel are oppressing us. We must fight back, and we must fight now!\n",
      "- label: Inciting violence\n",
      "\n",
      "- text: You're a worthless piece of shit, you stupid nigger. Go eat a bucket of fried chicken, you dumb monkey.\n",
      "- label: Slurs and trope\n",
      "\n",
      "- text: peta campaigns against keeping wild animals in zoos are right, let's switch them for some  nigger apes! they are fucking abhorrent\n",
      "- label: Dehumanization\n",
      "\n",
      "- text: Donald Trump is smelly pig.\n",
      "- label:\u001b[0m\u001b[32m Insult\n",
      "\n",
      "Please note that the examples provided are not appropriate or respectful, and should not be used to express hateful or discriminatory views towards any group of people.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = pipeline(text_input)\n",
    "continuation = response[0]['generated_text'].replace(text_input, \"\")\n",
    "    \n",
    "print(colored(text_input, \"red\") + colored(continuation, \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6d77cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mClassify the following sentence into categories below\n",
      "\n",
      "Sentence:[black = monkey]\n",
      "Here are categories:\n",
      "- Severe slurs and tropes: severe, repetitive usage of slurs, or racist/sexist tropes where the context is to harass or intimidate others\n",
      "\n",
      "- Other: None of above.\n",
      "\n",
      "- Hateful references: references forms of violence or violent events where a protected category was the primary target or victims, where the intent is to harass. This includes, but is not limited to media or text that refers to or depicts:genocides, (e.g., the Holocaust); lynchings.\n",
      "\n",
      "- Inciting violence: content intended to incite violence against a protected category\n",
      "\n",
      "- Moderate intimidate: moderate, isolated usage where the context is to harass or intimidate others\n",
      "\n",
      "- Inciting discriminate: inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category, e.g., “If you go to a [religious group] store, you are supporting those [slur], let’s stop giving our money to these [religious slur].” This may not include content intended as political in nature, such as political commentary or content relating to boycotts or protests.\n",
      "\n",
      "- Inciting harass: inciting others to harass members of a protected category on or off platform, e.g., “I’m sick of these [religious group] thinking they are better than us, if any of you see someone wearing a [religious symbol of the religious group], grab it off them and post pics!“\n",
      "\n",
      "- Inciting fear: inciting fear or spreading fearful stereotypes about a protected category, including asserting that members of a protected category are more likely to take part in dangerous or illegal activities, e.g., “all [religious group] are terrorists.”\n",
      "\n",
      "- Dehumanization: dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.\u001b[0m\u001b[32m\n",
      "\n",
      "- Microaggressions: subtle, often unintentional expressions or behaviors that convey negative or derogatory messages to members of a protected category, e.g., asking a person of color where they are “really from,” assuming a woman’s sexual orientation based on her appearance, or making jokes that demean a person’s religion or ethnicity.\n",
      "\n",
      "- Gaslighting: manipulating or distorting information to make someone question their own perceptions, memories, or sanity, often to gain power or control over them.\n",
      "\n",
      "- Minimization: downplaying the severity or impact of a form of discrimination or harassment, often to avoid taking responsibility for addressing it.\n",
      "\n",
      "- Blaming the victim: blaming the victim of discrimination or harassment for the abuse they have suffered, often by implying that they were somehow to blame for the abuse\u001b[0m\n",
      "\n",
      "\n",
      "- Microaggressions: subtle, often unintentional expressions or behaviors that convey negative or derogatory messages to members of a protected category, e.g., asking a person of color where they are “really from,” assuming a woman’s sexual orientation based on her appearance, or making jokes that demean a person’s religion or ethnicity.\n",
      "\n",
      "- Gaslighting: manipulating or distorting information to make someone question their own perceptions, memories, or sanity, often to gain power or control over them.\n",
      "\n",
      "- Minimization: downplaying the severity or impact of a form of discrimination or harassment, often to avoid taking responsibility for addressing it.\n",
      "\n",
      "- Blaming the victim: blaming the victim of discrimination or harassment for the abuse they have suffered, often by implying that they were somehow to blame for the abuse\n"
     ]
    }
   ],
   "source": [
    "response = classify_by_twitter(\"black = monkey\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621e06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4651 [00:01<1:51:49,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mClassify the following sentence into categories below\n",
      "\n",
      "Sentence:[wommennnnnn are dirt]\n",
      "Here are categories:\n",
      "- Inciting discriminate: inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category, e.g., “If you go to a [religious group] store, you are supporting those [slur], let’s stop giving our money to these [religious slur].” This may not include content intended as political in nature, such as political commentary or content relating to boycotts or protests.\n",
      "\n",
      "- Inciting violence: content intended to incite violence against a protected category\n",
      "\n",
      "- Moderate intimidate: moderate, isolated usage where the context is to harass or intimidate others\n",
      "\n",
      "- Hateful references: references forms of violence or violent events where a protected category was the primary target or victims, where the intent is to harass. This includes, but is not limited to media or text that refers to or depicts:genocides, (e.g., the Holocaust); lynchings.\n",
      "\n",
      "- Severe slurs and tropes: severe, repetitive usage of slurs, or racist/sexist tropes where the context is to harass or intimidate others\n",
      "\n",
      "- Other: None of above.\n",
      "\n",
      "- Inciting fear: inciting fear or spreading fearful stereotypes about a protected category, including asserting that members of a protected category are more likely to take part in dangerous or illegal activities, e.g., “all [religious group] are terrorists.”\n",
      "\n",
      "- Dehumanization: dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.\n",
      "\n",
      "- Inciting harass: inciting others to harass members of a protected category on or off platform, e.g., “I’m sick of these [religious group] thinking they are better than us, if any of you see someone wearing a [religious symbol of the religious group], grab it off them and post pics!“\u001b[0m\u001b[32m\n",
      "\n",
      "- Other: None of above.\n",
      "\n",
      "Please select the appropriate category for the sentence provided.\u001b[0m\n",
      "\n",
      "\n",
      "- Other: None of above.\n",
      "\n",
      "Please select the appropriate category for the sentence provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/4651 [00:02<1:34:46,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mClassify the following sentence into categories below\n",
      "\n",
      "Sentence:[ggggggggayyyyyyyyys r dirrrrrrrrrrrtttttt]\n",
      "Here are categories:\n",
      "- Moderate intimidate: moderate, isolated usage where the context is to harass or intimidate others\n",
      "\n",
      "- Inciting violence: content intended to incite violence against a protected category\n",
      "\n",
      "- Dehumanization: dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.\n",
      "\n",
      "- Inciting discriminate: inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category, e.g., “If you go to a [religious group] store, you are supporting those [slur], let’s stop giving our money to these [religious slur].” This may not include content intended as political in nature, such as political commentary or content relating to boycotts or protests.\n",
      "\n",
      "- Severe slurs and tropes: severe, repetitive usage of slurs, or racist/sexist tropes where the context is to harass or intimidate others\n",
      "\n",
      "- Inciting fear: inciting fear or spreading fearful stereotypes about a protected category, including asserting that members of a protected category are more likely to take part in dangerous or illegal activities, e.g., “all [religious group] are terrorists.”\n",
      "\n",
      "- Hateful references: references forms of violence or violent events where a protected category was the primary target or victims, where the intent is to harass. This includes, but is not limited to media or text that refers to or depicts:genocides, (e.g., the Holocaust); lynchings.\n",
      "\n",
      "- Inciting harass: inciting others to harass members of a protected category on or off platform, e.g., “I’m sick of these [religious group] thinking they are better than us, if any of you see someone wearing a [religious symbol of the religious group], grab it off them and post pics!“\n",
      "\n",
      "- Other: None of above.\u001b[0m\u001b[32m\n",
      "\n",
      "Please select the appropriate category for the given sentence.\u001b[0m\n",
      "\n",
      "\n",
      "Please select the appropriate category for the given sentence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/4651 [00:11<6:09:11,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mClassify the following sentence into categories below\n",
      "\n",
      "Sentence:[w o m e n a r e t r a s h]\n",
      "Here are categories:\n",
      "- Dehumanization: dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.\n",
      "\n",
      "- Inciting violence: content intended to incite violence against a protected category\n",
      "\n",
      "- Inciting harass: inciting others to harass members of a protected category on or off platform, e.g., “I’m sick of these [religious group] thinking they are better than us, if any of you see someone wearing a [religious symbol of the religious group], grab it off them and post pics!“\n",
      "\n",
      "- Inciting fear: inciting fear or spreading fearful stereotypes about a protected category, including asserting that members of a protected category are more likely to take part in dangerous or illegal activities, e.g., “all [religious group] are terrorists.”\n",
      "\n",
      "- Inciting discriminate: inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category, e.g., “If you go to a [religious group] store, you are supporting those [slur], let’s stop giving our money to these [religious slur].” This may not include content intended as political in nature, such as political commentary or content relating to boycotts or protests.\n",
      "\n",
      "- Hateful references: references forms of violence or violent events where a protected category was the primary target or victims, where the intent is to harass. This includes, but is not limited to media or text that refers to or depicts:genocides, (e.g., the Holocaust); lynchings.\n",
      "\n",
      "- Moderate intimidate: moderate, isolated usage where the context is to harass or intimidate others\n",
      "\n",
      "- Other: None of above.\n",
      "\n",
      "- Severe slurs and tropes: severe, repetitive usage of slurs, or racist/sexist tropes where the context is to harass or intimidate others\u001b[0m\u001b[32m.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/4651 [00:12<4:27:31,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mClassify the following sentence into categories below\n",
      "\n",
      "Sentence:[trrrrrrrassssshhh = bbbblllllllllackkkkkkkks]\n",
      "Here are categories:\n",
      "- Moderate intimidate: moderate, isolated usage where the context is to harass or intimidate others\n",
      "\n",
      "- Hateful references: references forms of violence or violent events where a protected category was the primary target or victims, where the intent is to harass. This includes, but is not limited to media or text that refers to or depicts:genocides, (e.g., the Holocaust); lynchings.\n",
      "\n",
      "- Inciting violence: content intended to incite violence against a protected category\n",
      "\n",
      "- Other: None of above.\n",
      "\n",
      "- Severe slurs and tropes: severe, repetitive usage of slurs, or racist/sexist tropes where the context is to harass or intimidate others\n",
      "\n",
      "- Inciting fear: inciting fear or spreading fearful stereotypes about a protected category, including asserting that members of a protected category are more likely to take part in dangerous or illegal activities, e.g., “all [religious group] are terrorists.”\n",
      "\n",
      "- Dehumanization: dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.\n",
      "\n",
      "- Inciting discriminate: inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category, e.g., “If you go to a [religious group] store, you are supporting those [slur], let’s stop giving our money to these [religious slur].” This may not include content intended as political in nature, such as political commentary or content relating to boycotts or protests.\n",
      "\n",
      "- Inciting harass: inciting others to harass members of a protected category on or off platform, e.g., “I’m sick of these [religious group] thinking they are better than us, if any of you see someone wearing a [religious symbol of the religious group], grab it off them and post pics!“\u001b[0m\u001b[32m\n",
      "\n",
      "- Other: None of above.\n",
      "\n",
      "Please select the appropriate category for the given sentence.\u001b[0m\n",
      "\n",
      "\n",
      "- Other: None of above.\n",
      "\n",
      "Please select the appropriate category for the given sentence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/4651 [00:14<3:32:24,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mClassify the following sentence into categories below\n",
      "\n",
      "Sentence:[trans people are filth! look in the mirror!]\n",
      "Here are categories:\n",
      "- Other: None of above.\n",
      "\n",
      "- Inciting violence: content intended to incite violence against a protected category\n",
      "\n",
      "- Hateful references: references forms of violence or violent events where a protected category was the primary target or victims, where the intent is to harass. This includes, but is not limited to media or text that refers to or depicts:genocides, (e.g., the Holocaust); lynchings.\n",
      "\n",
      "- Severe slurs and tropes: severe, repetitive usage of slurs, or racist/sexist tropes where the context is to harass or intimidate others\n",
      "\n",
      "- Moderate intimidate: moderate, isolated usage where the context is to harass or intimidate others\n",
      "\n",
      "- Inciting fear: inciting fear or spreading fearful stereotypes about a protected category, including asserting that members of a protected category are more likely to take part in dangerous or illegal activities, e.g., “all [religious group] are terrorists.”\n",
      "\n",
      "- Inciting harass: inciting others to harass members of a protected category on or off platform, e.g., “I’m sick of these [religious group] thinking they are better than us, if any of you see someone wearing a [religious symbol of the religious group], grab it off them and post pics!“\n",
      "\n",
      "- Dehumanization: dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.\n",
      "\n",
      "- Inciting discriminate: inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category, e.g., “If you go to a [religious group] store, you are supporting those [slur], let’s stop giving our money to these [religious slur].” This may not include content intended as political in nature, such as political commentary or content relating to boycotts or protests.\u001b[0m\u001b[32m\n",
      "\n",
      "- Other: none of the above.\n",
      "\n",
      "Please select the appropriate category for the given sentence.\u001b[0m\n",
      "\n",
      "\n",
      "- Other: none of the above.\n",
      "\n",
      "Please select the appropriate category for the given sentence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/4651 [00:16<3:06:57,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mClassify the following sentence into categories below\n",
      "\n",
      "Sentence:[trrrrrrrassssshhh = blacks]\n",
      "Here are categories:\n",
      "- Inciting violence: content intended to incite violence against a protected category\n",
      "\n",
      "- Other: None of above.\n",
      "\n",
      "- Inciting discriminate: inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category, e.g., “If you go to a [religious group] store, you are supporting those [slur], let’s stop giving our money to these [religious slur].” This may not include content intended as political in nature, such as political commentary or content relating to boycotts or protests.\n",
      "\n",
      "- Dehumanization: dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.\n",
      "\n",
      "- Severe slurs and tropes: severe, repetitive usage of slurs, or racist/sexist tropes where the context is to harass or intimidate others\n",
      "\n",
      "- Hateful references: references forms of violence or violent events where a protected category was the primary target or victims, where the intent is to harass. This includes, but is not limited to media or text that refers to or depicts:genocides, (e.g., the Holocaust); lynchings.\n",
      "\n",
      "- Moderate intimidate: moderate, isolated usage where the context is to harass or intimidate others\n",
      "\n",
      "- Inciting harass: inciting others to harass members of a protected category on or off platform, e.g., “I’m sick of these [religious group] thinking they are better than us, if any of you see someone wearing a [religious symbol of the religious group], grab it off them and post pics!“\n",
      "\n",
      "- Inciting fear: inciting fear or spreading fearful stereotypes about a protected category, including asserting that members of a protected category are more likely to take part in dangerous or illegal activities, e.g., “all [religious group] are terrorists.”\u001b[0m\u001b[32m\n",
      "\n",
      "- Other: content that does not fit into any of the above categories.\n",
      "\n",
      "Please select the appropriate category for the sentence provided.\u001b[0m\n",
      "\n",
      "\n",
      "- Other: content that does not fit into any of the above categories.\n",
      "\n",
      "Please select the appropriate category for the sentence provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/4651 [00:17<2:33:46,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mClassify the following sentence into categories below\n",
      "\n",
      "Sentence:[trrrrrrrassssshhh = bbbbblaccccccccks]\n",
      "Here are categories:\n",
      "- Dehumanization: dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.\n",
      "\n",
      "- Hateful references: references forms of violence or violent events where a protected category was the primary target or victims, where the intent is to harass. This includes, but is not limited to media or text that refers to or depicts:genocides, (e.g., the Holocaust); lynchings.\n",
      "\n",
      "- Inciting fear: inciting fear or spreading fearful stereotypes about a protected category, including asserting that members of a protected category are more likely to take part in dangerous or illegal activities, e.g., “all [religious group] are terrorists.”\n",
      "\n",
      "- Severe slurs and tropes: severe, repetitive usage of slurs, or racist/sexist tropes where the context is to harass or intimidate others\n",
      "\n",
      "- Inciting violence: content intended to incite violence against a protected category\n",
      "\n",
      "- Inciting discriminate: inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category, e.g., “If you go to a [religious group] store, you are supporting those [slur], let’s stop giving our money to these [religious slur].” This may not include content intended as political in nature, such as political commentary or content relating to boycotts or protests.\n",
      "\n",
      "- Moderate intimidate: moderate, isolated usage where the context is to harass or intimidate others\n",
      "\n",
      "- Other: None of above.\n",
      "\n",
      "- Inciting harass: inciting others to harass members of a protected category on or off platform, e.g., “I’m sick of these [religious group] thinking they are better than us, if any of you see someone wearing a [religious symbol of the religious group], grab it off them and post pics!“\u001b[0m\u001b[32m\n",
      "\n",
      "\n",
      "Please select the appropriate category for the given sentence.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "Please select the appropriate category for the given sentence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/4651 [00:26<5:26:13,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mClassify the following sentence into categories below\n",
      "\n",
      "Sentence:[trrrrrrrassssshhh = theblacks]\n",
      "Here are categories:\n",
      "- Inciting discriminate: inciting others to discriminate in the form of denial of support to the economic enterprise of an individual or group because of their perceived membership in a protected category, e.g., “If you go to a [religious group] store, you are supporting those [slur], let’s stop giving our money to these [religious slur].” This may not include content intended as political in nature, such as political commentary or content relating to boycotts or protests.\n",
      "\n",
      "- Inciting violence: content intended to incite violence against a protected category\n",
      "\n",
      "- Dehumanization: dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.\n",
      "\n",
      "- Moderate intimidate: moderate, isolated usage where the context is to harass or intimidate others\n",
      "\n",
      "- Inciting fear: inciting fear or spreading fearful stereotypes about a protected category, including asserting that members of a protected category are more likely to take part in dangerous or illegal activities, e.g., “all [religious group] are terrorists.”\n",
      "\n",
      "- Severe slurs and tropes: severe, repetitive usage of slurs, or racist/sexist tropes where the context is to harass or intimidate others\n",
      "\n",
      "- Hateful references: references forms of violence or violent events where a protected category was the primary target or victims, where the intent is to harass. This includes, but is not limited to media or text that refers to or depicts:genocides, (e.g., the Holocaust); lynchings.\n",
      "\n",
      "- Other: None of above.\n",
      "\n",
      "- Inciting harass: inciting others to harass members of a protected category on or off platform, e.g., “I’m sick of these [religious group] thinking they are better than us, if any of you see someone wearing a [religious symbol of the religious group], grab it off them and post pics!“\u001b[0m\u001b[32m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/installation/anaconda3/envs/negative/lib/python3.8/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../postprocess/all_examples_0601_hate.csv\", sep = '\\t')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "labels = []\n",
    "for sentence in tqdm(df[\"sentence\"]):\n",
    "    label = classify_by_twitter(sentence)\n",
    "    print(label)\n",
    "    labels.append(label)\n",
    "    \n",
    "df[\"twitter\"] = labels\n",
    "df.to_csv(\"updated_all_examples_0601_hate.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38cbd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T02:48:58.841554936Z",
     "start_time": "2023-08-13T02:48:58.351089639Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_pipeline = pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pipeline(\"Dehumanization: dehumanization of a group of people based on their religion, caste, age, disability, serious disease, national origin, race, ethnicity, gender, gender identity, or sexual orientation.\\n\\nIs the following sentence Dehumanization? \\n\\nSentence: 'I want to kill all muslims'\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(r'\\n Category:(.*?)$', label)\n",
    "category = match.group(1).strip()\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b658f164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8321b7a15d493da163f5b8633d88a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=200) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "spaces_between_special_tokens is deprecated and will be removed in transformers v5. It was adding spaces between `added_tokens`, not special tokens, and does not exist in our fast implementation. Future tokenizers will handle the decoding process on a per-model rule.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Is the following sentence hate, counter hate or neutral? And why? \\\\n \\\\n Sentence: \\'I want to kill all muslims\\'\".\\n\\nI would classify the sentence as hate speech. The sentence expresses a desire to harm or kill an entire religious group, which is a violation of human rights and goes against basic principles of dignity and respect for all individuals. It is important to recognize and challenge hate speech in all its forms, including when it is directed towards religious or ethnic groups. Neutral'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)\n",
    "\n",
    "\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, pipeline\n",
    "\n",
    "model_path = \"/data/shared/llama2/llama/7B-Chat/\"\n",
    "\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
    "model = LlamaForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=200,\n",
    "    device=0,\n",
    "   \n",
    ")\n",
    "pipeline(\"Is the following sentence hate, counter hate or neutral? And why? \\\\n \\\\n Sentence: 'I want to kill all muslims'\", max_length=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
